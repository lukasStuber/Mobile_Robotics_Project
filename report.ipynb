{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Robotics Project - Final Report\n",
    "\n",
    "Group Members:\n",
    "- ESCOYEZ, Antoine Jacques Richard, 335564\n",
    "- POUSSIN, Jean-Baptiste Marie Alexandre, 303127\n",
    "- KOCKISCH, Matthias Hugues Jörg, 303000\n",
    "- STUBER, Lukas, 289304\n",
    "\n",
    "Professor:\n",
    "\n",
    "Prof. MONDADA, Francesco\n",
    "\n",
    "\n",
    "EPFL, 11.12.2022\n",
    "Course MICRO-452 Basics of Mobile Robotics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "The goal of this project of Basics Mobile Robotics project was the control of a two wheeled Thymio robot. The environment of the robot is a map designed by the group members. On the map there needs to be obstacles into which the robot must not drive. According to the map and certain fixed obstacles present on the map, a global path from the start to the goal must be calculated using computer vision from an external camera. The start is the initial location of the Thymio, the goal can be placed by the user. On its path to the goal the robot needs to be able to detect and avoid unforeseen obstacles that are added manually. For better tracking of the path some kind of filtering must be used to improve the state estimation of the robot. The camera image serves as measurement for the latter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed Description of our Choices\n",
    "Our group chose the map to be a parking space with two centered rows of parking spaces. The yellow lines mark the edges of these spaces and are the fixed obstacles used in the global path planning. The robot is neither allowed to cross the yellow lines nor leave the map while following this path. The camera is fixed above the map and oversees the entire situation (robot, lines, free spaces, occupied spaces). To facilitate the detection of the position and orientation of the robot in the images, we stuck two coloured stickers on the top of the robot, right above its wheels. The left sticker is green, the right one is blue. The computer vision algorithm uses these two points to determine the center of the wheels axis and the orientation of the robot. The goal is a free parking space indicated by a red paper square. The unexpected obstacles (ignored by the computer vision) are other Thymio robots. The estimated state correction is done with the help of a Kalman filter whose measurement is the location of the Thymio in the camera images.\n",
    "\n",
    "<img src=\"Map.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "We use an *AUKEY 1080P - 30 fps* camera as the input for the computer vision. It is fixed on a stand (a lamp) and sees the entire map from above. Its position does not change during the operation of the robot.\n",
    "\n",
    "To enable a clear and stable detection of the objects on the map, a series of adjustments are done before the object detection. The image processing is done in HSV representation of the image. The procedure is automatically started when the main function is executed. It includes:\n",
    "- Adjust the luminosity <font color='red'>????</font>\n",
    "- Detection of the outer borders of the map\n",
    "- Adjust the red upper and lower thresholds <font color='red'>????</font>\n",
    "- Adjust the green upper and lower thresholds <font color='red'>????</font>\n",
    "- Adjust the blue upper and lower thresholds <font color='red'>????</font>\n",
    "- Adjust the yellow upper and lower thresholds <font color='red'>????</font>\n",
    "\n",
    "<font color='red'>Describe the steps of the computer vision to find the colorized map.</font>\n",
    "\n",
    "The computer vision algorithm abstracts the picture of the map leaving only the relevant objects in solid colours: map surface (black), robot (green and blue spots), obstacle lines (yellow), goal (red)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Path Planning\n",
    "The global path planning is done using the A* algorithm, as seen in Exercise 5 of the course. It uses the simplified map generated by the computer vision part as input. The typical size of this image is <font color='red'>????</font>, which is far too large for the A* algorithm to finish in an acceptable time. To reduce the size of the image, a convolutional filter is applied to the pixels. Its size (the variable ``kernel``) can be chosen by the user. The filter divides the image from the vision part into square patches of side length $2\\:\\times$ ``kernel`` $+\\:1$. The output pixel is 0 if:\n",
    "- all the pixels in the patch are black (free space)\n",
    "- at least one of the pixels is green or blue (robot position)\n",
    "- at least one of the pixels is red (goal position)\n",
    "The output is 1 if:\n",
    "- at least one of the pixels is yellow (obstacle line)\n",
    "The result of this filtering is a map of typical size 60 by 120 pixels (depending on the size of the input map) where the free, start and goal space is 0 and the obstacle space is 1.\n",
    "\n",
    "This reduced map and the start and goal positions are fed into the A* algorithm that calculates the optimal global path from the start to the goal. The calculated path is a series of coordinates in the reduced map format. To serve as directions for the Thymio, these coordinates need to be resized to the original map (multiplied by the reduction factor $2\\:\\times$ ``kernel`` $+\\:1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Control\n",
    "The class ThymioControl in the file ``control.py`` solely handles the interactions between the PC and the Thymio through the ``tdmclient`` library, and contains the related higher-level algorithms for path following and obstacle avoidance. It thus controls the speeds of the robot’s wheels depending on the robot coordinates given by the Kalman filtering module, and then sends the speeds it applied back to the latter.\n",
    "\n",
    "```python\n",
    "def __init__(self):\n",
    "    self.client = ClientAsync()\n",
    "    self.node = aw(self.client.wait_for_node())\n",
    "    aw(self.node.lock())\n",
    "    self.position = [0,0]\n",
    "    self.angle = 0\n",
    "    self.speed_target = (0,0)\n",
    "# path following\n",
    "    self.stop_planned = False\n",
    "    self.path = [(0,0)]\n",
    "    self.path_index = 0\n",
    "# obstacle avoidance\n",
    "    self.proxs = np.zeros(5)\n",
    "    self.obst_direction = 0\n",
    "# timers\n",
    "    self.stop_timer = Timer(0, self.stop)\n",
    "    self.move_timer = RepeatedTimer(MOVE_INTERVAL, self.navigation)\n",
    "```\n",
    "\n",
    "The function ``navigation()``, controlling both path following and obstacle avoidance, is called by the RepeatedTimer ``move_timer`` at a period ``MOVE_INTERVAL``. This function first reads the values of the proximity sensors of the Thymio, and then starts either an obstacle avoidance step if a significant value is read in fron tin the robot, or a path following step if not. This switch is controlled by the value of ``PROX_THRESHOLD``, which is set too 1000, or around 65 millimeters, for our application. The timer interval ``MOVE_INTERVAL`` is set to ``0.21`` seconds to leave time for both fetching of the sensor values and setting new motor values, both having a set duration of 100 milliseconds. ``move_timer`` is started by the function ``follow_path()``, which is called from the main program.\n",
    "\n",
    "```python\n",
    "def navigation(self):\n",
    "    self.get_prox()\n",
    "    if np.any(self.proxs > PROX_THRESHOLD):\n",
    "        self.avoid_obstacles()\n",
    "    else: self.move_to_goal()\n",
    "\n",
    "def follow_path(self):\n",
    "    self.move_timer.start()\n",
    "```\n",
    "\n",
    "The most basic movement function is ``move(l_speed, r_speed)`` which simply sends the desired speeds to the Thymio and records the current speed-target. This communication with the robot has a standard duration of 100 milliseconds, which makes an efficient PID controller running on the computer impossible. A PID running on the Thymio itself was also not desirable due to the frequent sending of observed positions and fetching of estimated positions, requiring event-listeners on both machines, adding more delays to the movement. Running a PID and odometry on the Thymio itself is further impeded by the robot's inability to calculate with floating point values (running odometry on the computer instead would require speed-updates at a very high frequency, which is completely impossible due to the previous reasons).\n",
    "\n",
    "We thus decided to greatly reduce the amount of communications by setting a constant speed for all movements and estimating its duration; the commands sent to the robot are now only the initial start of the movement, and the stopping command after a set duration. In this case, no (relevant) code is flashed onto the Thymio.\n",
    "\n",
    "```python\n",
    "def move(self, l_speed, r_speed=None):\n",
    "    if r_speed is None: r_speed = l_speed\n",
    "    aw(self.node.set_variables({\"motor.left.target\": [int(l_speed)],\n",
    "                \"motor.right.target\": [int(r_speed)]}))\n",
    "    self.speed_target = (l_speed, r_speed)\n",
    "\n",
    "```\n",
    "\n",
    "### Path following\n",
    "The simple path following algorithm function ``move_to_goal()`` can be reduced to the following pseudo-code:\n",
    "\n",
    "<pre>\n",
    "calculate distance to goal  \n",
    "if distance is above threshold:  \n",
    "    calculate angle to goal\n",
    "    if angle is above threshold:\n",
    "        <i>re-orient robot</i>\n",
    "    else:\n",
    "        <i>move robot</i>\n",
    "else:\n",
    "    increment goal index in path array\n",
    "    if index surpasses the length of the path:\n",
    "        stop the movement timer\n",
    "</pre>\n",
    "\n",
    "Both italic lines represent a movement of the robot. For these functions, the movement duration is first estimated using the real-world speed conversion constant ``SPEED_TO_MMS``, which has been experimentally found to be $0.32\\:(mm/s)^{-1}$ (at our chosen speed of ``STANDARD_SPEED = 200``, the Thymio moves 32 centimeters in 5 seconds). This duration is capped at 0.5 seconds to allow re-orientation in case of an asynchronous Kalman update.\n",
    "\n",
    "The distance threshold ``DIST_TOL`` determines the point at which a goal is reached, while the angle threshold ``ANGLE_TOL`` triggers a re-orientation of the robot on its way to a goal. Their values were set to 10 millimeters and 0.1 rad = 5.73° respectively, which allows precise enough movement and good path following without any issues.\n",
    "\n",
    "```python\n",
    "def move_to_goal(self):\n",
    "    if self.stop_planned: return\n",
    "    goal = self.path[self.path_index]\n",
    "    dist = math.sqrt((goal[0] - self.position[0])**2 + (goal[1] - self.position[1])**2)\n",
    "    if dist > DIST_TOL:\n",
    "        angle = (math.atan2(goal[1] - self.position[1], goal[0] - self.position[0])\n",
    "                    - self.angle + math.pi) % (2*math.pi) - math.pi\n",
    "        if abs(angle) > ANGLE_TOL:\n",
    "            direction = 1 if angle > 0 else -1 # 1 = turn left, -1 = turn right\n",
    "            t = abs(angle)*WHEEL_DIST / (2*STANDARD_SPEED*SPEED_TO_MMS)\n",
    "            t = min(t, MAX_TIME) # allow Kalman updates\n",
    "            self.timed_move(direction*STANDARD_SPEED, -direction*STANDARD_SPEED, t)\n",
    "        else:\n",
    "            t = dist / (STANDARD_SPEED*SPEED_TO_MMS)\n",
    "            t = min(t, MAX_TIME) # allow Kalman updates\n",
    "            self.timed_move(STANDARD_SPEED, STANDARD_SPEED, t)\n",
    "    else:\n",
    "        self.path_index += 1\n",
    "        if self.path_index >= len(self.path): self.end_path()\n",
    "```\n",
    "\n",
    "The function shown above lacks a few lines at its beginning, which handle the end of the obstacle avoidance procedure; these will be shown and addressed in the corresponding section.\n",
    "\n",
    "The final move duration is used to program ``stop_timer``, which simply stops the robot and resets the boolean ``stop_planned`` to allows re-entry into ``move_to_goal()``. The timer is programmed by the function ``timed_move()``, which also sets ``stop_planned`` that prohibits any new command from ``move_to_goal()``. Since the ``stop()`` function needs to send new motor-targets to the Thymio, the communication delay is first subtracted from the timer duration. \n",
    "\n",
    "```python\n",
    "def stop(self):\n",
    "    self.stop_planned = False\n",
    "    self.move(0)\n",
    "    \n",
    "def timed_move(self, l_speed, r_speed, time):\n",
    "    self.stop_planned = True\n",
    "    self.stop_timer = Timer(time - 0.1, self.stop)  # compensate stopping delay\n",
    "    self.move(l_speed, r_speed)\n",
    "    self.stop_timer.start()\n",
    "```\n",
    "\n",
    "The ``end_path()`` function at the very end of ``move_to_goal()`` stops the robot and the movement timers. It then is the only function in the project that sends Aseba-code to the Thymio, which crudely plays the refrain of the electronic track \"Crab Rave\" by producer \"Noisestorm\" until the center button is pressed.\n",
    "\n",
    "```python\n",
    "def end_path(self):\n",
    "    self.move_timer.stop()\n",
    "    self.stop_timer.cancel()\n",
    "    self.stop()\n",
    "    self.crab_rave()\n",
    "    \n",
    "def crab_rave(self):\n",
    "    program = '''\n",
    "var note[19] = [2349, 1976, 1568, 1568, 2349, 2349, 1760, 1397, 1397, 2349, 2349, 1760, 1397, 1397, 2094, 2094, 1319, 1319, 1397]\n",
    "var duration[19] = [2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2]\n",
    "var i = 1\n",
    "var play = 1\n",
    "call sound.freq(note[0]/2, 8*duration[0])\n",
    "onevent sound.finished\n",
    "if play == 1 then\n",
    "    call sound.freq(note[i]/2, 8*duration[i])\n",
    "    i = i + 1\n",
    "    if i == 19 then\n",
    "        i = 0\n",
    "    else\n",
    "    end\n",
    "end\n",
    "onevent button.center\n",
    "play = 0\n",
    "    '''\n",
    "    async def prog():\n",
    "        await self.node.compile(program)\n",
    "        await self.node.run()\n",
    "    self.client.run_async_program(prog)\n",
    "```\n",
    "\n",
    "The last function of the class, called ``keyboard()``, allows the user to control the Thymio's wheel speeds using their computer's WASD keys, albeit with the usual 100 millisecond delay between input and action. This code was used to control another Thymio on the map during testing and the demostration video.\n",
    "\n",
    "### Obstacle avoidance\n",
    "In case an obstacle is detected by the front proximity sensors, ``navigation()`` calls the function ``avoid_obstacles()``. This function first stops ``stop_timer`` and its boolean in case the path following function has activated it, then calculates the speeds of both wheels using a dot product on coefficients. These coefficients make the robot turn if the obstacle is detected on the sides, and move backwards when it lies right in front of the Thymio (since the readings are practically never symmetrical, the middle coefficient has never led to a draw by repetition). Furthermore, if the obstacle is only found at the extremities of the sensed space, the robot will keep moving forward at half its standard speed. The side on which the obstacle has been found is then saved in ``obst_direction``, the speed sent to the robot, and the function starts anew while ``navigation()`` detects a significant presence in front of the robot.\n",
    "\n",
    "```python\n",
    "def avoid_obstacles(self):\n",
    "    self.stop_planned = False\n",
    "    self.stop_timer.cancel()\n",
    "    speed = np.dot(self.proxs, [[3, -3], [1, -1], [-1, -1], [-1, 1], [-3, 3]])/100\n",
    "    if (np.sum(self.proxs[1:4]) < 30): # if no obstacle in front, move forward\n",
    "       speed[0] += STANDARD_SPEED/2; speed[1] += STANDARD_SPEED/2\n",
    "    self.obst_direction = 1 if speed[0] < speed[1] else -1 # go left when obstacle on left and vice versa\n",
    "    self.move(speed[0], speed[1])\n",
    "```\n",
    "\n",
    "Once the obstacle disappears or is completely avoided, the robot will re-enter ``move_to_goal()`` and use the last computed value of ``obst_direction`` to spurt forward while slightly turning towards the obstacle for ``OBST_TIME = 1`` seconds, in hopes of landing beyond it. This value along with ``OBST_SPEED`` and ``OBST_TURN_SPEED`` has been calibrated for driving past another immobile Thymio. It must be noted that the yellow lines of the map are ignored for the entire avoidance sequence, and also once the path following sets in again; these markings are only used during the pathfinding to place the checkpoints the robot has to travel through. The Thymio will also keep circling around the obstacle while the latter covers its next checkpoint.\n",
    "\n",
    "Here are the lines of code of ``move_to_goal()`` that weren't shown in the previous section:\n",
    "\n",
    "```python\n",
    "def move_to_goal(self):\n",
    "    if self.stop_planned: return\n",
    "    if self.obst_direction != 0: # avoid previously detected obstacle\n",
    "        self.timed_move(self.obst_direction*OBST_TURN_SPEED + OBST_SPEED,\n",
    "                        -self.obst_direction*OBST_TURN_SPEED + OBST_SPEED, OBST_TIME)\n",
    "        self.obst_direction = 0\n",
    "        return\n",
    "    goal = self.path[self.path_index] # start of path following code\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter\n",
    "The Kalman Filter is quite standard. It is a class with the following attributes:\n",
    "- the current state estimation, a vector with (x position, y position, orientation theta)\n",
    "- the current state estimation covariance matrix\n",
    "- the process uncertainty matrix (constant, describes the noise of the state propagation)\n",
    "- the measurement uncertainty matrix (constant, describes the noise of the measurement by the camera)\n",
    "- the observation matrix (constant, maps the state to the observation of the state), since all of the states can be measured, this is an identity matrix\n",
    "- the time stamp of the last time the filter was called (used for calculating the elapsed time)\n",
    "\n",
    "```python\n",
    "class Kalman:\n",
    "    def __init__(self):\n",
    "        # timestep for state propagation\n",
    "        self.dt = None\n",
    "        self.prev_time = None\n",
    "        # state\n",
    "        self.x = np.zeros((3, 1)) # state\n",
    "        self.P = 1000*np.ones((3,3)) # state covariance\n",
    "        # process noise\n",
    "        self.R = np.diag([NOISE_POS_XY, NOISE_POS_XY, NOISE_POS_THETA])\n",
    "        # measurement noise\n",
    "        self.Q = np.diag([NOISE_MEASURE_XY, NOISE_MEASURE_XY])\n",
    "        # Observation Matrix H\n",
    "        self.H = np.array([[1, 0, 0],\n",
    "                           [0, 1, 0],\n",
    "                           [0, 0, 1]])\n",
    "```\n",
    "\n",
    "and the following methods:\n",
    "- state_prop <br>\n",
    "It takes as input the speeds of the two wheels during the last timestep. From that it estimates the new position and state covariance matrix and updates the corresponding attributes. Because the state propagation includes sinus and cosinus calculations, it is not a linear system. To facilitate the calculations a first order approximation is used that linearizes the system. The error of the approximation is limited because the state_prop function is called every 25ms <font color='red'>????</font>. So, the involved angle is very small and so is the error of the linearization.\n",
    "\n",
    "```python\n",
    "def state_prop(self, u):\n",
    "        if self.prev_time is None: # initialisation\n",
    "            self.prev_time = time.time()\n",
    "            return\n",
    "        u = np.array(u)\n",
    "        self.dt = time.time() - self.prev_time\n",
    "        self.prev_time = time.time()\n",
    "        # https://ocw.mit.edu/courses/6-186-mobile-autonomous-systems-laboratory-january-iap-2005/764fafce112bed6482c61f1593bd0977_odomtutorial.pdf\n",
    "        (dx, dy) = self.dt*SPEED_TO_MMS*u # left and right displacements [mm]\n",
    "        da = -(dy - dx)/WHEEL_DIST # rotation angle [rad]\n",
    "        dc = (dx + dy)/2 # center displacement [mm]\n",
    "        (vx, vy) = SPEED_TO_MMS*u # left and right wheel speeds [mm/s]\n",
    "        vt = (vx + vy)/2 # translation speed [mm/s]\n",
    "        vr = -(vy - vx)/WHEEL_DIST # rotation speed [rad/s]\n",
    "        #print(\"angle is \", self.x[2])\n",
    "        sin = math.sin(self.x[2])\n",
    "        cos = math.cos(self.x[2])\n",
    "        # state propagation\n",
    "        self.x[0] = self.x[0] + dc*cos\n",
    "        self.x[1] = self.x[1] + dc*sin\n",
    "        self.x[2] = (self.x[2] + da) % (2*math.pi)\n",
    "        # transition function (state propagation matrix)\n",
    "        A = np.array([[1, 0, -self.dt*vt*sin],\n",
    "                      [0, 1,  self.dt*vt*cos],\n",
    "                      [0, 0, 1]])\n",
    "        # input transition matrix\n",
    "        L = np.array([[self.dt*vx/2*cos, -self.dt*vy/2*cos],\n",
    "                      [self.dt*vx/2*cos, -self.dt*vx/2*sin],\n",
    "                      [self.dt*vx/WHEEL_DIST, -self.dt*vy/WHEEL_DIST]])\n",
    "        # state covariance propagation\n",
    "        self.P = A@self.P@A.T + L@self.Q@L.T\n",
    "```\n",
    "- state_correct <br>\n",
    "It takes as input the measurement of the position and angle of the robot from the camera. It calculates the Kalman gain and corrects the state and state covariance. It takes quite some time to take an image with the camera and extract the position of the robot, which means that the correct function can only be called every 1.0s <font color='red'>????</font>.\n",
    "\n",
    "```python\n",
    "def state_correct(self, z):\n",
    "        z = np.reshape(z, (3,1))\n",
    "        K = self.P@self.H.T@np.linalg.inv(self.H@self.P@self.H.T + self.R) # kalman gain\n",
    "        self.x = self.x + K@(z - self.H@self.x) # state\n",
    "        self.P = (np.eye(3) - K@self.H)@self.P # state covariance\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function\n",
    "bla bla, maybe talk about the timers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "conclude conclude\n",
    "\n",
    "### Possible improvements\n",
    "- The pathfinding algorithm tends to return a jagged path, which can lead to unnecessary movements of the robot even after removing most of the intermediary points. This could be improved by adding a turning penalty to the A* algorithm.\n",
    "- The obstacle avoidance is very basic, and assumes the next checkpoint is beyond the obstacle. Since this is not always the case, the robot might spurt past the obstacle and then have to turn around. The spurt could be replaced by a mixed movement, composed of both obstacle avoidance and path following.\n",
    "- The path following is also very crude: it only tries to reach the next checkpoint and does not take into account the checkpoints after that. This means that the robot might overshoot the checkpoint and then turn around, even though it would be faster to carry on to the next one. Similarly, after going off-path during the obstacle avoidance, rejoining the path at a later checkpoint might be faster. This might be achieved by, for example, projecting the current position onto the path.\n",
    "- The Kalman filter obviously suffers from an offset on the position due to perspective, since the reference points on the Thymio are not on the ground plane. This leads to the robot driving closer to the center of the map than it should during path following, and some Kalman corrections confusing the odometric estimations. This could be solved with this trigonometric offset being taken into account in the state correction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "from parking_segmentation import *\n",
    "from color_segmentation import *\n",
    "from color_centroids import *\n",
    "from discretize_map import *\n",
    "from control import ThymioControl\n",
    "from Kalman import Kalman\n",
    "from constants import *\n",
    "from RepeatedTimer import RepeatedTimer\n",
    "\n",
    "# IMAGE PROCESSING\n",
    "id_camera = 1\n",
    "##[Parking segmentation]\n",
    "corners, destination_corners = set_parking_limits(id_camera)\n",
    "##[Color segmentation]\n",
    "segmentation, refined_color_dict_HSV, kernels, openings = get_color_mask(id_camera, corners, destination_corners, real_size=(NOMINAL_AREA_LENGTH, NOMINAL_AREA_WIDTH))\n",
    "cv.namedWindow(\"Segmentation Result\")\n",
    "cv.imshow(\"Segmentation Result\", segmentation)\n",
    "key = cv.waitKey(0)\n",
    "cv.destroyWindow(\"Segmentation Result\")\n",
    "##[Thymio and objective localization]\n",
    "centroids = {'goal': (0, 0), 'thymio': (0, 0), 'green': (0, 0), 'blue': (0, 0)}\n",
    "theta_thymio = 0\n",
    "localization = None\n",
    "\n",
    "kalman = Kalman()\n",
    "thymio = ThymioControl()\n",
    "\n",
    "def compute_centroids():\n",
    "    global centroids, theta_thymio, localization\n",
    "    centroids, theta_thymio, localization = get_centroids(id_camera, corners, destination_corners, refined_color_dict_HSV, kernels, openings, prev_centroids=centroids, real_size=(NOMINAL_AREA_LENGTH, NOMINAL_AREA_WIDTH), real_time=False)\n",
    "    #print(\"centroids at\", centroids['thymio'][0], centroids['thymio'][1])\n",
    "    #print(\"thymio angle at \", theta_thymio)\n",
    "    kalman.state_correct(np.array([centroids['thymio'][0], centroids['thymio'][1], theta_thymio]))\n",
    "    thymio.position = (kalman.x[0, 0], kalman.x[1, 0])\n",
    "    thymio.angle = kalman.x[2, 0]\n",
    "\n",
    "def odometry():\n",
    "    kalman.state_prop(thymio.speed_target)\n",
    "    thymio.position = (kalman.x[0, 0], kalman.x[1, 0])\n",
    "    thymio.angle = kalman.x[2, 0]\n",
    "    #print(thymio.position[0], thymio.position[1], thymio.angle*180/math.pi)\n",
    "\n",
    "# def plot_localization():\n",
    "#     global localization\n",
    "#     cv.namedWindow(\"Localization Result\")\n",
    "#     cv.imshow(\"Localization Result\", localization)\n",
    "#     key = cv.waitKey(30)\n",
    "#     cv.destroyWindow(\"Localization Result\")\n",
    "\n",
    "# initialise position and path\n",
    "compute_centroids()\n",
    "kalman.set_state((centroids['thymio'][0], centroids['thymio'][1], theta_thymio))\n",
    "thymio.position = (centroids['thymio'][0], centroids['thymio'][1])\n",
    "thymio.angle = theta_thymio\n",
    "path = discretize_map(segmentation, centroids)\n",
    "thymio.set_path(path)\n",
    "\n",
    "# start updating position and follow path\n",
    "image_timer = RepeatedTimer(1.5, compute_centroids)\n",
    "odometry_timer = RepeatedTimer(ODOMETRY_INTERVAL, odometry)\n",
    "image_timer.start()\n",
    "odometry_timer.start()\n",
    "thymio.follow_path()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e50035b3dfd539dbd2dca26cbba61024e04488120c7d4591534a01642a5bb0ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
